{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqow4dyeehsy",
    "outputId": "8f041cfb-6957-451e-8a32-1690168110f9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ReLU,LSTM, BatchNormalization,Normalization\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from tensorflow_model_optimization.quantization.keras import QuantizeConfig\n",
    "from tensorflow_model_optimization.quantization.keras import quantize_annotate_layer\n",
    "from tensorflow_model_optimization.quantization.keras import quantize_annotate_model\n",
    "from tensorflow_model_optimization.quantization.keras import quantize_apply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders unzipped to Cuvette\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_file_path = 'zipped_folders.zip'\n",
    "output_dir = 'Cuvette'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "print(f\"Folders unzipped to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model to Tflite for Cuvette 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93992, 10)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette45/data_train.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "\n",
    "def quantized_model():\n",
    "    num_features = 10\n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(128, activation='relu')(deep_input)\n",
    "    hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "    hidden3 = Dense(32, activation='relu')(hidden1)\n",
    "    hidden4 = Dense(16, activation='relu')(hidden2)\n",
    "    concatenated_layers = concatenate([wide_input, hidden4])\n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "base_model = quantized_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette45',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y_train,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette45')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 05:48:52.553485: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-08-05 05:48:52.553502: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-08-05 05:48:52.553599: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: model_cuvette45\n",
      "2024-08-05 05:48:52.554891: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-08-05 05:48:52.554897: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: model_cuvette45\n",
      "2024-08-05 05:48:52.558834: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-08-05 05:48:52.594970: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: model_cuvette45\n",
      "2024-08-05 05:48:52.605768: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 52170 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR='model_cuvette45'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model45-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.int8'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_8:0', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01612352766096592, -107), 'quantization_parameters': {'scales': array([0.01612353], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_7:0', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06140619516372681, -123), 'quantization_parameters': {'scales': array([0.0614062], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 15, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 = 0.01612353\n",
    "zero_point_input_1 = -107\n",
    "scale_input_2 = 0.0614062\n",
    "zero_point_input_2 = -123\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette45/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=scaler.transform(x)\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    #print(quantized_output)\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "    #print(probability)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "\n",
    "    # Check accuracy\n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model to Tflite For Cuvette 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187176, 10)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette47/data_train.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_model():\n",
    "    num_features = 10\n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(128, activation='relu')(deep_input)\n",
    "    hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "    hidden3 = Dense(32, activation='relu')(hidden1)\n",
    "    hidden4 = Dense(16, activation='relu')(hidden2)\n",
    "    concatenated_layers = concatenate([wide_input, hidden4])\n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "base_model = quantized_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette47',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y_train,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette47')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 05:49:15.459341: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-08-05 05:49:15.459357: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-08-05 05:49:15.459450: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: model_cuvette47\n",
      "2024-08-05 05:49:15.460725: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-08-05 05:49:15.460731: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: model_cuvette47\n",
      "2024-08-05 05:49:15.464583: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-08-05 05:49:15.500865: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: model_cuvette47\n",
      "2024-08-05 05:49:15.510050: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 50600 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR='model_cuvette47'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model47-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.int8'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_10:0', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.016223566606640816, -106), 'quantization_parameters': {'scales': array([0.01622357], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_9:0', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06672343611717224, -123), 'quantization_parameters': {'scales': array([0.06672344], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 15, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 = 0.01622357\n",
    "zero_point_input_1 = -106\n",
    "scale_input_2 = 0.06672344\n",
    "zero_point_input_2 = -123\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette47/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=scaler.transform(x)\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model to Tflite for Cuvette 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93952, 10)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette22/data_train.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_model():\n",
    "    num_features = 10\n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(512, activation='relu')(deep_input)\n",
    "    hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "    hidden3 = Dense(128, activation='relu')(hidden2)\n",
    "    hidden4 = Dense(64, activation='relu')(hidden3)\n",
    "    hidden5 = Dense(32, activation='relu')(hidden4)\n",
    "    hidden6 = Dense(16, activation='relu')(hidden5)\n",
    "    hidden7=Dense(256, activation='relu')(deep_input)\n",
    "    hidden8=Dense(128, activation='relu')(deep_input)\n",
    "    hidden9=Dense(64, activation='relu')(deep_input)\n",
    "    hidden10=Dense(32, activation='relu')(deep_input)\n",
    "    concatenated_layers = concatenate([wide_input, hidden6,hidden7,hidden8,hidden9,hidden10])\n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "base_model = quantized_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette22',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y_train,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette22')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 05:50:22.615968: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-08-05 05:50:22.615989: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-08-05 05:50:22.616094: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: model_cuvette22\n",
      "2024-08-05 05:50:22.618683: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-08-05 05:50:22.618691: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: model_cuvette22\n",
      "2024-08-05 05:50:22.626856: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-08-05 05:50:22.704052: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: model_cuvette22\n",
      "2024-08-05 05:50:22.723185: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 107091 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR='model_cuvette22'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model22-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.int8'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_16:0', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06492095440626144, -123), 'quantization_parameters': {'scales': array([0.06492095], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_15:0', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (3.3731067180633545, -128), 'quantization_parameters': {'scales': array([3.3731067], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 36, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 = 0.06492095\n",
    "zero_point_input_1 = -123\n",
    "scale_input_2 = 3.3731067\n",
    "zero_point_input_2 = -128\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette22/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=scaler.transform(x)\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model for Cuvette 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93944, 10)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette9/data_train.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_model():\n",
    "    num_features = 10\n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(1024, activation='relu')(deep_input)\n",
    "    hidden2 = Dense(512, activation='relu')(hidden1)\n",
    "    hidden3 = Dense(256, activation='relu')(hidden2)\n",
    "    hidden4 = Dense(128, activation='relu')(hidden3)\n",
    "    hidden5 = Dense(64, activation='relu')(hidden4)\n",
    "    hidden6 = Dense(32, activation='relu')(hidden5)\n",
    "    hidden7 = Dense(16, activation='relu')(hidden6)\n",
    "    hidden8=Dense(128, activation='relu')(wide_input)\n",
    "    hidden9=Dense(64, activation='relu')(hidden8)\n",
    "    hidden10=Dense(32, activation='relu')(hidden9)\n",
    "    concatenated_layers = concatenate([wide_input, hidden7,hidden8,hidden9,hidden10])\n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "base_model = quantized_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette9',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y_train,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette9')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 05:51:53.969899: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-08-05 05:51:53.969922: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-08-05 05:51:53.970041: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: model_cuvette9\n",
      "2024-08-05 05:51:53.973058: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-08-05 05:51:53.973065: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: model_cuvette9\n",
      "2024-08-05 05:51:53.982800: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-08-05 05:51:54.065792: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: model_cuvette9\n",
      "2024-08-05 05:51:54.086908: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 116866 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR='model_cuvette9'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model9-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.int8'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_18:0', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.027775896713137627, -116), 'quantization_parameters': {'scales': array([0.0277759], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_17:0', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.027775896713137627, -116), 'quantization_parameters': {'scales': array([0.0277759], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 39, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 = 0.0277759\n",
    "zero_point_input_1 = -116\n",
    "scale_input_2 = 0.0277759\n",
    "zero_point_input_2 = -116\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette9/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=scaler.transform(x)\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model to Tflite for Cuvette 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette29/data_train.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_model():\n",
    "    num_features = 10\n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(512, activation='relu')(deep_input)\n",
    "    hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "    hidden3 = Dense(128, activation='relu')(hidden2)\n",
    "    hidden4 = Dense(64, activation='relu')(hidden3)\n",
    "    hidden5 = Dense(32, activation='relu')(hidden4)\n",
    "    hidden6 = Dense(16, activation='relu')(hidden5)\n",
    "    hidden7=Dense(512, activation='relu')(deep_input)\n",
    "    hidden8=Dense(256, activation='relu')(deep_input)\n",
    "    hidden9=Dense(128, activation='relu')(deep_input)\n",
    "    hidden10=Dense(64, activation='relu')(deep_input)\n",
    "    hidden11=Dense(32, activation='relu')(deep_input)\n",
    "    concatenated_layers = concatenate([wide_input, hidden6,hidden7,hidden8,hidden9,hidden10,hidden11])\n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "base_model = quantized_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette29',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y_train,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette29')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR='model_cuvette29'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model29-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 =21384.0390625\n",
    "zero_point_input_1 = -128\n",
    "scale_input_2 = 21384.0390625\n",
    "zero_point_input_2 = -128\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette29/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x.iloc[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model to Tflite for Cuvette37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94024, 10)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette37/data_train.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modified_model():\n",
    "    num_features = 10  \n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(200,activation='relu')(deep_input)\n",
    "    hidden2 = Dense(190,activation='relu')(hidden1)\n",
    "    hidden3 = Dense(180,activation='relu')(hidden2)\n",
    "    hidden4 = Dense(170,activation='relu')(hidden3)\n",
    "    hidden5 = Dense(160,activation='relu')(hidden4)\n",
    "    hidden6 = Dense(150,activation='relu')(hidden5)\n",
    "    hidden7 = Dense(100,activation='relu')(hidden6)\n",
    "    hidden8 = Dense(80,activation='relu')(hidden7)\n",
    "    hidden9 = Dense(60,activation='relu')(hidden8)\n",
    "    hidden10 = Dense(32,activation='relu')(hidden9)\n",
    "    parallel_input2= Dense(128,activation='relu')(deep_input)\n",
    "    parallel_input3= Dense(64, activation='relu')(deep_input)\n",
    "    parallel_input4= Dense(32,activation='relu')(wide_input)\n",
    "    parallel_input1= Dense(256, activation='relu')(deep_input)\n",
    "    parallel_input5 = Dense(512, activation='relu')(deep_input)\n",
    "    concatenated_layers = concatenate([wide_input,hidden10,parallel_input1,parallel_input2,parallel_input3,parallel_input4,parallel_input5])\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "base_model = create_modified_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette37',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y_train,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette37')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 05:52:44.507095: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-08-05 05:52:44.507119: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-08-05 05:52:44.507237: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: model_cuvette37\n",
      "2024-08-05 05:52:44.510889: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-08-05 05:52:44.510898: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: model_cuvette37\n",
      "2024-08-05 05:52:44.522832: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-08-05 05:52:44.631250: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: model_cuvette37\n",
      "2024-08-05 05:52:44.658175: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 150938 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR='model_cuvette37'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model37-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.int8'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_25:0', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.502932071685791, -127), 'quantization_parameters': {'scales': array([0.5029321], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_26:0', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.502932071685791, -127), 'quantization_parameters': {'scales': array([0.5029321], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 52, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 = 0.5029321\n",
    "zero_point_input_1 = -127\n",
    "scale_input_2 =0.5029321\n",
    "zero_point_input_2 = -127\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette37/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=scaler.transform(x)\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting Model to Tflite for Cuvette 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FOR CUVETTE 0 ONLY####\n",
    "train_df=pd.read_csv('Cuvette/Cuvette0/data_train.csv')\n",
    "test_df=pd.read_csv('Cuvette/Cuvette0/data.csv')\n",
    "concat=pd.concat([train_df,test_df],ignore_index=True)\n",
    "concat.to_csv('jointcuvette0.csv')\n",
    "joint_df=pd.read_csv('jointcuvette0.csv')\n",
    "train_csv=joint_df.iloc[:,2:]\n",
    "x=train_csv.iloc[:,:-1]\n",
    "y=train_csv.iloc[:,-1]\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modified_model():\n",
    "    num_features = 10  \n",
    "    wide_input = Input(shape=(num_features,))\n",
    "    deep_input = Input(shape=(num_features,))\n",
    "    hidden1 = Dense(200,activation='relu')(deep_input)\n",
    "    hidden2 = Dense(190,activation='relu')(hidden1)\n",
    "    hidden3 = Dense(180,activation='relu')(hidden2)\n",
    "    hidden4 = Dense(170,activation='relu')(hidden3)\n",
    "    hidden5 = Dense(160,activation='relu')(hidden4)\n",
    "    hidden6 = Dense(150,activation='relu')(hidden5)\n",
    "    hidden7 = Dense(100,activation='relu')(hidden6)\n",
    "    hidden8 = Dense(80,activation='relu')(hidden7)\n",
    "    hidden9 = Dense(60,activation='relu')(hidden8)\n",
    "    hidden10 = Dense(32,activation='relu')(hidden9)\n",
    "    parallel_input2= Dense(128,activation='relu')(deep_input)\n",
    "    parallel_input3= Dense(64, activation='relu')(deep_input)\n",
    "    parallel_input4= Dense(32,activation='relu')(wide_input)\n",
    "    parallel_input1= Dense(256, activation='relu')(deep_input)\n",
    "    parallel_input5 = Dense(512, activation='relu')(deep_input)\n",
    "    concatenated_layers = concatenate([wide_input,hidden10,parallel_input1,parallel_input2,parallel_input3,parallel_input4,parallel_input5])\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(concatenated_layers)\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "base_model = create_modified_model()\n",
    "annotated_model = quantize_annotate_model(base_model)\n",
    "\n",
    "quant_aware_model = quantize_apply(annotated_model)\n",
    "\n",
    "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Recall','Precision'])\n",
    "quant_aware_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='model_cuvette0',\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.fit((x_train,x_train),y,epochs=15,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_cuvette0')\n",
    "\n",
    "model.evaluate((x_test,x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(x_train.shape[0]):\n",
    "        sample = x_train[i:i+1].astype(np.float32) \n",
    "        yield [sample, sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR='model_cuvette0'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "with open('model0-QAT_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_input(data, scale, zero_point):\n",
    "    normalized_data = (data / scale) + zero_point\n",
    "    quantized_data = np.clip(normalized_data, -128, 127).astype(np.int8)\n",
    "    return quantized_data\n",
    "def dequantize_output(data, scale, zero_point):\n",
    "    return (data.astype(np.float32) - zero_point) * scale\n",
    "scale_input_1 = 0.49051696\n",
    "zero_point_input_1 = -128\n",
    "scale_input_2 =0.4905169\n",
    "zero_point_input_2 = -128\n",
    "scale_output = 0.00390625\n",
    "zero_point_output = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cuvette/Cuvette0/data.csv')\n",
    "df=df.iloc[:,1:]\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x=scaler.transform(x)\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(x)):  \n",
    "    input = x[i].astype(np.float32)\n",
    "    input = np.expand_dims(input, axis=0)  \n",
    "    quantized_input_1 = quantize_input(input, scale_input_1, zero_point_input_1)\n",
    "    quantized_input_2 = quantize_input(input, scale_input_2, zero_point_input_2)\n",
    "    interpreter.set_tensor(input_details[0]['index'], quantized_input_1)\n",
    "    interpreter.set_tensor(input_details[1]['index'], quantized_input_2)\n",
    "    \n",
    "   \n",
    "    interpreter.invoke()\n",
    "\n",
    "    quantized_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    probability = dequantize_output(quantized_output, scale_output,zero_point_output)\n",
    "   \n",
    "    predicted_label = 1 if probability > threshold else 0  \n",
    "    if predicted_label == y[i]:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data for Inference and Saving in .H format\n",
    "## Change the Cuvette Numbers to save data of different Cuvettes. Also change the respective cuvette numbers of the file being saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Cuvette0/data.csv' ### Change Cuvette Number Here \n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('=', '')\n",
    "\n",
    "measurements = df.iloc[:, 1:]  \n",
    "formatted_str = \"MeasurementData0 measurements0[] = {\\n\" ### Change Cuvette Number Here ###\n",
    "for index, row in measurements.iterrows():\n",
    "    formatted_str += \"    {\" + \", \".join(map(str, row.values)) + \"},\\n\"\n",
    "formatted_str = formatted_str.strip(',\\n') + \"\\n};\"\n",
    "\n",
    "output_file_path = 'tflite0.h' ### Change Cuvette Number Here ###\n",
    "\n",
    "with open(output_file_path, 'w') as file: \n",
    "    file.write(formatted_str)\n",
    "\n",
    "print(f\"Data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Mean and Std Dev Values for Scaling Data for each Cuvette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuvette0: Mean = [ 5877.16034771  5853.1180876   5898.2671013   6230.81216984\n",
      "  6144.21220328  5313.55600134  6394.80966232  5799.38943497\n",
      "  7687.98324975 17319.17853561], Std Dev = [ 34040.66973224  32555.89200022  35204.9188014   38370.11124596\n",
      "  38272.84587819  37246.49561343  39360.85567054  50842.48953944\n",
      "  99405.48895803 232254.43844386]\n",
      "Cuvette9: Mean = [263005.00630163 107228.73537427 182464.92101678 305580.3369667\n",
      " 315750.93708592 316616.04445201 321487.12511283 335841.54783275\n",
      " 234127.44907605 311829.21977348], Std Dev = [ 870806.30216227  325278.70199715  553725.92898619 1083730.05335389\n",
      " 1121533.38050594 1125740.11780339 1141739.68742835 1194981.44422409\n",
      "  712991.48054722 1057456.74927629]\n",
      "Cuvette22: Mean = [214696.88924557  23818.43831744  57672.67536614 106311.83428134\n",
      " 113646.35336342 114540.78697207 119389.56726839 129504.56879257\n",
      "  97153.15690565 295715.22246253], Std Dev = [ 730746.43161753   72752.5896946   176497.21949464  350258.21619293\n",
      "  375907.8088742   379821.57705414  396324.98443289  432989.20608965\n",
      "  316899.23971688 1042513.73119661]\n",
      "Cuvette29: Mean = [ 65398.19043567   6114.45499489   9480.12557012  16370.99658781\n",
      "  17754.20707965  17221.44029101  19519.85236555  23317.08232641\n",
      "  23192.91884786 120284.10594792], Std Dev = [220007.59699421  23324.21416651  32750.97110445  53095.01958088\n",
      "  57559.20076675  56289.04656765  72763.20658961 111605.69694261\n",
      " 176745.18007924 468579.96487016]\n",
      "Cuvette37: Mean = [22279.53101336  5607.05090615  5878.98712669  6744.9753765\n",
      "  6786.96835702  5984.29847698  7482.49852804  8019.32012252\n",
      " 10552.66953118 49246.47540203], Std Dev = [ 75072.37609014  16830.38911429  17649.25719835  20309.27049679\n",
      "  20450.9778758   18061.54586877  43302.22244195  84829.67017441\n",
      " 148278.11190376 311266.189395  ]\n",
      "Cuvette45: Mean = [415880.3316878  312708.3256958  398829.50905609 369891.40257894\n",
      " 374843.69781258 375431.95330666 378360.12639374 383881.86218402\n",
      " 443516.04716146 449311.49115669], Std Dev = [1378727.49115844  948131.64974938 1210089.90674477 1228356.01247843\n",
      " 1245925.41936408 1248701.90572005 1257861.06935382 1276336.69423946\n",
      " 1344655.61010865 1501521.77770609]\n",
      "Cuvette47: Mean = [608849.04579647 636529.87719366 633594.34718126 595496.84609138\n",
      " 591990.60721887 590820.35166047 593228.33780827 594909.16961576\n",
      " 644724.65739625 600410.42277642], Std Dev = [1957389.16032315 1985083.97026398 1982686.45137855 1929087.66294351\n",
      " 1924312.08642231 1925582.60693328 1929780.27595846 1935818.06190744\n",
      " 2010645.3481033  1955323.31671569]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def process_csv_file(file_number):\n",
    "    file_path = f'Cuvette/Cuvette{file_number}/data_train.csv'\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f'File not found: {file_path}')\n",
    "        return None, None\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df=df.iloc[:,1:]\n",
    "    x=df.iloc[:,:-1]\n",
    "    y=df.iloc[:,-1]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "\n",
    "    mean = scaler.mean_\n",
    "    std_dev = scaler.scale_\n",
    "    \n",
    "    print(f'Cuvette{file_number}: Mean = {mean}, Std Dev = {std_dev}')\n",
    "    \n",
    "    return mean, std_dev\n",
    "file_numbers = [0, 9 ,22, 29,37,45,47,]\n",
    "\n",
    "for file_number in file_numbers:\n",
    "    process_csv_file(file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "BSA",
   "language": "python",
   "name": "blood-spec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e1349f1a1a94659988d1594dfa8e844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6499a9cedd314b6092f6327daed74e9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed7aca26add845d091dbe675e68f8ebe",
      "placeholder": "",
      "style": "IPY_MODEL_0e1349f1a1a94659988d1594dfa8e844",
      "value": "4.821 MB of 4.821 MB uploaded (0.194 MB deduped)\r"
     }
    },
    "8d81d858cffb42289995c6dc3dee877b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92417b14cd1a48d6b2f34d3627d2c788": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d81d858cffb42289995c6dc3dee877b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c35f36af20354127b7d688033b13694c",
      "value": 1
     }
    },
    "bdc617f95d16453c843a9d779df36332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6499a9cedd314b6092f6327daed74e9d",
       "IPY_MODEL_92417b14cd1a48d6b2f34d3627d2c788"
      ],
      "layout": "IPY_MODEL_eee417d8a18643cab0dbdf400ce4077e"
     }
    },
    "c35f36af20354127b7d688033b13694c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed7aca26add845d091dbe675e68f8ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eee417d8a18643cab0dbdf400ce4077e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
